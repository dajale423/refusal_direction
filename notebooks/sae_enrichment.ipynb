{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "import gc\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import torch as t\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig,\n",
    "    SAETrainingRunner,\n",
    "    upload_saes_to_huggingface,\n",
    ")\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from sae_vis import SaeVisConfig, SaeVisData, SaeVisLayoutConfig\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "device = \"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 45541.31 MB\n",
      "Allocated GPU Memory: 15740.26 MB\n",
      "Cached GPU Memory: 15930.00 MB\n"
     ]
    }
   ],
   "source": [
    "## check memory usage\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    gpu_id = 0  # Set to your target GPU ID\n",
    "    total_memory = t.cuda.get_device_properties(gpu_id).total_memory\n",
    "    allocated_memory = t.cuda.memory_allocated(gpu_id)\n",
    "    cached_memory = t.cuda.memory_reserved(gpu_id)\n",
    "\n",
    "    print(f\"Total GPU Memory: {total_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Allocated GPU Memory: {allocated_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached GPU Memory: {cached_memory / 1024**2:.2f} MB\")\n",
    "elif t.backends.mps.is_available():\n",
    "    # MPS (Metal Performance Shaders) for Mac\n",
    "    print(\"MPS is available.\")\n",
    "    # Note: As of now, PyTorch doesn't provide direct memory management functions for MPS\n",
    "    print(\"Memory information is not available for MPS.\")\n",
    "else:\n",
    "    print(\"Neither CUDA nor MPS is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del gemma2\n",
    "# del gemma2_sae\n",
    "\n",
    "t.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output tensor of SAE activations for advbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read from advbench.json file\n",
    "with open('../dataset/processed/advbench.json', 'r') as file:\n",
    "    advbench_data = json.load(file)\n",
    "\n",
    "len(advbench_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stacked_sae_acts_post\n",
    "del gemma2_sae\n",
    "t.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "\n",
    "sae_name = \"gemma-scope-2b-pt-res-canonical\"\n",
    "sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in range(11)]  # 0 through 10\n",
    "\n",
    "\n",
    "gemma2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gemma-2-2b-it\", device=device)\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "for sae_id in sae_ids:\n",
    "    gemma2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=sae_name,\n",
    "        sae_id=sae_id,\n",
    "        device=str(device),\n",
    "    )\n",
    "\n",
    "    all_sae_acts_post = []\n",
    "\n",
    "    for item in advbench_data:\n",
    "        prompt = item['instruction']\n",
    "        \n",
    "        # Get top activations on final token\n",
    "        _, cache = gemma2.run_with_cache_with_saes(\n",
    "            prompt,\n",
    "            saes=[gemma2_sae],\n",
    "            stop_at_layer=gemma2_sae.cfg.hook_layer + 1,\n",
    "        )\n",
    "        sae_acts_post = cache[f\"{gemma2_sae.cfg.hook_name}.hook_sae_acts_post\"][0, -1, :]\n",
    "        all_sae_acts_post.append(sae_acts_post)\n",
    "\n",
    "    # Stack all sae_acts_post tensors\n",
    "    stacked_sae_acts_post = torch.stack(all_sae_acts_post)\n",
    "\n",
    "    print(f\"SAE ID: {sae_id}\")\n",
    "    print(f\"Shape of stacked tensor: {stacked_sae_acts_post.shape}\")\n",
    "    print(f\"Total number of non-zero activations: {(stacked_sae_acts_post != 0).sum().item()}\")\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(f'../data/sae_acts/{sae_name}/{sae_id}', exist_ok=True)\n",
    "\n",
    "    # Save the stacked_sae_acts_post tensor\n",
    "    torch.save(stacked_sae_acts_post, f'../data/sae_acts/{sae_name}/{sae_id}_advbench.pt')\n",
    "\n",
    "    # Print confirmation message\n",
    "    print(f\"Stacked SAE activations saved to '../data/sae_acts/{sae_name}/{sae_id}_advbench.pt'\")\n",
    "    print(\"---\")\n",
    "\n",
    "    del stacked_sae_acts_post\n",
    "    del gemma2_sae\n",
    "    t.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get average activations for each sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/sae_lens/sae.py:143: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "\n",
    "gpt2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "gpt2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",\n",
    "    device=str(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.73k/2.73k [00:00<00:00, 87.8kB/s]\n",
      "Downloading readme: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.35k/7.35k [00:00<00:00, 180kB/s]\n",
      "/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/sae_lens/training/activations_store.py:246: UserWarning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "gpt2_act_store = ActivationsStore.from_sae(\n",
    "    model=gpt2,\n",
    "    sae=gpt2_sae,\n",
    "    streaming=True,\n",
    "    store_batch_size_prompts=16,\n",
    "    n_batches_in_buffer=32,\n",
    "    device=str(device),\n",
    ")\n",
    "\n",
    "# Example of how you can use this:\n",
    "tokens = gpt2_act_store.get_batch_tokens()\n",
    "assert tokens.shape == (gpt2_act_store.store_batch_size_prompts, gpt2_act_store.context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:25<00:00, 15.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_frac_active(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    act_store: ActivationsStore,\n",
    "    # latent_idx: int,\n",
    "    total_batches: int = 400,\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays the activation histogram for a particular latent, computed across `total_batches` batches from `act_store`.\n",
    "    \"\"\"\n",
    "    sae_acts_post_hook_name = f\"{sae.cfg.hook_name}.hook_sae_acts_post\"\n",
    "    all_positive_acts = []\n",
    "\n",
    "    all_positive_acts = t.zeros(sae.cfg.d_sae, device=device)\n",
    "    total_acts = 0\n",
    "\n",
    "    for i in tqdm(range(total_batches)):\n",
    "        tokens = act_store.get_batch_tokens()\n",
    "        _, cache = model.run_with_cache_with_saes(\n",
    "            tokens,\n",
    "            saes=[sae],\n",
    "            stop_at_layer=sae.cfg.hook_layer + 1,\n",
    "            names_filter=[sae_acts_post_hook_name],\n",
    "        )\n",
    "        acts = cache[sae_acts_post_hook_name]\n",
    "        all_positive_acts += (acts > 0).sum(dim=(0, 1))\n",
    "        total_acts += acts.shape[0] * acts.shape[1]\n",
    "\n",
    "    frac_active = all_positive_acts / total_acts\n",
    "\n",
    "    return frac_active\n",
    "\n",
    "\n",
    "frac_active = get_frac_active(gpt2, gpt2_sae, gpt2_act_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1123, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_active[3731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_grad_enabled(False)\n",
    "\n",
    "sae_name = \"gemma-scope-2b-pt-res-canonical\"\n",
    "sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in range(11)]  # 0 through 10\n",
    "\n",
    "gemma2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gemma-2-2b-it\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [03:40<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_0/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0323, 0.0013, 0.0100,  ..., 0.0024, 0.0030, 0.0010], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [05:25<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_1/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0011, 0.0016, 0.0276,  ..., 0.0004, 0.0009, 0.0008], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [07:08<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_2/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0012, 0.0075, 0.0009,  ..., 0.0008, 0.0064, 0.0012], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [08:50<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_3/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0032, 0.0028, 0.0156,  ..., 0.0007, 0.0013, 0.0059], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [10:35<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_4/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0007, 0.0138, 0.0029,  ..., 0.0040, 0.0014, 0.0067], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [12:33<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_5/width_16k/canonical\n",
      "Fraction of activations: tensor([1.2868e-02, 1.6076e-02, 1.8198e-03,  ..., 8.3618e-05, 1.6998e-04,\n",
      "        4.5691e-03], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [14:04<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_6/width_16k/canonical\n",
      "Fraction of activations: tensor([1.7288e-04, 2.4805e-03, 3.6662e-03,  ..., 9.7809e-05, 3.8969e-03,\n",
      "        3.2462e-03], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [15:48<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_7/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0008, 0.0101, 0.0005,  ..., 0.0010, 0.0026, 0.0043], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [17:32<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_8/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0034, 0.0097, 0.0066,  ..., 0.0054, 0.0058, 0.0058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████▋                                                                                                               | 97/400 [04:40<14:34,  2.89s/it]"
     ]
    }
   ],
   "source": [
    "for sae_id in sae_ids:\n",
    "    gemma2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=sae_name,\n",
    "        sae_id=sae_id,\n",
    "        device=str(device),\n",
    "    )\n",
    "\n",
    "    gemma2_act_store = ActivationsStore.from_sae(\n",
    "        model=gemma2,\n",
    "        sae=gemma2_sae,\n",
    "        streaming=True,\n",
    "        store_batch_size_prompts=16,\n",
    "        n_batches_in_buffer=32,\n",
    "        device=str(device),\n",
    "    )\n",
    "\n",
    "    frac_active = get_frac_active(gemma2, gemma2_sae, gemma2_act_store)\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(f'../data/sae_acts/{sae_name}/{sae_id}', exist_ok=True)\n",
    "\n",
    "    # Save the stacked_sae_acts_post tensor\n",
    "    t.save(frac_active, f'../data/sae_acts/{sae_name}/{sae_id}/frac_active.pt')\n",
    "    print(f\"SAE ID: {sae_id}\")\n",
    "    print(f\"Fraction of activations: {frac_active}\")\n",
    "\n",
    "    del gemma2_sae\n",
    "    t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gemma2_sae\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
