{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "import gc\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import torch as t\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig,\n",
    "    SAETrainingRunner,\n",
    "    upload_saes_to_huggingface,\n",
    ")\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from sae_vis import SaeVisConfig, SaeVisData, SaeVisLayoutConfig\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "device = \"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 45541.31 MB\n",
      "Allocated GPU Memory: 0.00 MB\n",
      "Cached GPU Memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "## check memory usage\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    gpu_id = 0  # Set to your target GPU ID\n",
    "    total_memory = t.cuda.get_device_properties(gpu_id).total_memory\n",
    "    allocated_memory = t.cuda.memory_allocated(gpu_id)\n",
    "    cached_memory = t.cuda.memory_reserved(gpu_id)\n",
    "\n",
    "    print(f\"Total GPU Memory: {total_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Allocated GPU Memory: {allocated_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached GPU Memory: {cached_memory / 1024**2:.2f} MB\")\n",
    "elif t.backends.mps.is_available():\n",
    "    # MPS (Metal Performance Shaders) for Mac\n",
    "    print(\"MPS is available.\")\n",
    "    # Note: As of now, PyTorch doesn't provide direct memory management functions for MPS\n",
    "    print(\"Memory information is not available for MPS.\")\n",
    "else:\n",
    "    print(\"Neither CUDA nor MPS is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del gemma2\n",
    "# del gemma2_sae\n",
    "\n",
    "t.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output tensor of SAE activations for advbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31323\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read from advbench.json file\n",
    "with open('../dataset/processed/advbench.json', 'r') as file:\n",
    "    advbench_data = json.load(file)\n",
    "\n",
    "len(advbench_data)\n",
    "\n",
    "# Read from advbench.json file\n",
    "with open('../dataset/processed/alpaca.json', 'r') as file:\n",
    "    alpaca_data = json.load(file)\n",
    "\n",
    "print(len(alpaca_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_data_500 = alpaca_data[:500]\n",
    "alpaca_data_10000 = alpaca_data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alpaca_data_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stacked_sae_acts_post' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mstacked_sae_acts_post\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gemma2_sae\n\u001b[1;32m      3\u001b[0m t\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stacked_sae_acts_post' is not defined"
     ]
    }
   ],
   "source": [
    "del stacked_sae_acts_post\n",
    "del gemma2_sae\n",
    "t.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sae_activations(sae_name, sae_ids, data, suffix):\n",
    "    t.set_grad_enabled(False)\n",
    "    gemma2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gemma-2-2b-it\", device=device)\n",
    "\n",
    "    for sae_id in sae_ids:\n",
    "        gemma2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "            release=sae_name,\n",
    "            sae_id=sae_id,\n",
    "            device=str(device),\n",
    "        )\n",
    "    \n",
    "        all_sae_acts_post = []\n",
    "    \n",
    "        for item in data:\n",
    "            prompt = item['instruction']\n",
    "            \n",
    "            # Get top activations on final token\n",
    "            _, cache = gemma2.run_with_cache_with_saes(\n",
    "                prompt,\n",
    "                saes=[gemma2_sae],\n",
    "                stop_at_layer=gemma2_sae.cfg.hook_layer + 1,\n",
    "            )\n",
    "            sae_acts_post = cache[f\"{gemma2_sae.cfg.hook_name}.hook_sae_acts_post\"][0, -1, :]\n",
    "            all_sae_acts_post.append(sae_acts_post)\n",
    "    \n",
    "        # Stack all sae_acts_post tensors\n",
    "        stacked_sae_acts_post = torch.stack(all_sae_acts_post)\n",
    "    \n",
    "        print(f\"SAE ID: {sae_id}\")\n",
    "        print(f\"Shape of stacked tensor: {stacked_sae_acts_post.shape}\")\n",
    "        print(f\"Total number of non-zero activations: {(stacked_sae_acts_post != 0).sum().item()}\")\n",
    "    \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(f'../data/sae_acts/{sae_name}/{sae_id}', exist_ok=True)\n",
    "    \n",
    "        # Save the stacked_sae_acts_post tensor\n",
    "        torch.save(stacked_sae_acts_post.cpu(), f'../data/sae_acts/{sae_name}/{sae_id}_{suffix}.pt')\n",
    "    \n",
    "        # Print confirmation message\n",
    "        print(f\"Stacked SAE activations saved to '../data/sae_acts/{sae_name}/{sae_id}_{suffix}.pt'\")\n",
    "        print(\"---\")\n",
    "    \n",
    "        del stacked_sae_acts_post\n",
    "        del gemma2_sae\n",
    "        t.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "Loading checkpoint shards:   0%|                                                                                                                                   | 0/2 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in range(11)]  # 0 through 10\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in [5]]  # 0 through 10\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sae_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/width_16k/canonical\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)]  \u001b[38;5;66;03m# 0 through 10\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msave_sae_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43msae_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpaca_data_10000\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpaca_10000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36msave_sae_activations\u001b[0;34m(sae_name, sae_ids, data, suffix)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_sae_activations\u001b[39m(sae_name, sae_ids, data, suffix):\n\u001b[1;32m      2\u001b[0m     t\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m     gemma2: HookedSAETransformer \u001b[38;5;241m=\u001b[39m \u001b[43mHookedSAETransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma-2-2b-it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sae_id \u001b[38;5;129;01min\u001b[39;00m sae_ids:\n\u001b[1;32m      6\u001b[0m         gemma2_sae, cfg_dict, sparsity \u001b[38;5;241m=\u001b[39m SAE\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      7\u001b[0m             release\u001b[38;5;241m=\u001b[39msae_name,\n\u001b[1;32m      8\u001b[0m             sae_id\u001b[38;5;241m=\u001b[39msae_id,\n\u001b[1;32m      9\u001b[0m             device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(device),\n\u001b[1;32m     10\u001b[0m         )\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:1298\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     center_unembed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;66;03m# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# match the HookedTransformer parameter names.\u001b[39;00m\n\u001b[0;32m-> 1298\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mloading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pretrained_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mofficial_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfrom_pretrained_kwargs\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# Create the HookedTransformer object\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   1304\u001b[0m     cfg,\n\u001b[1;32m   1305\u001b[0m     tokenizer,\n\u001b[1;32m   1306\u001b[0m     move_to_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1307\u001b[0m     default_padding_side\u001b[38;5;241m=\u001b[39mdefault_padding_side,\n\u001b[1;32m   1308\u001b[0m )\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformer_lens/loading_from_pretrained.py:1752\u001b[0m, in \u001b[0;36mget_pretrained_state_dict\u001b[0;34m(official_model_name, cfg, hf_model, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         hf_model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m   1746\u001b[0m             official_model_name,\n\u001b[1;32m   1747\u001b[0m             torch_dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1748\u001b[0m             token\u001b[38;5;241m=\u001b[39mhuggingface_token,\n\u001b[1;32m   1749\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1750\u001b[0m         )\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1752\u001b[0m         hf_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m            \u001b[49m\u001b[43mofficial_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuggingface_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1759\u001b[0m     \u001b[38;5;66;03m# Load model weights, and fold in layer norm weights\u001b[39;00m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m hf_model\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:4014\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4005\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4007\u001b[0m     (\n\u001b[1;32m   4008\u001b[0m         model,\n\u001b[1;32m   4009\u001b[0m         missing_keys,\n\u001b[1;32m   4010\u001b[0m         unexpected_keys,\n\u001b[1;32m   4011\u001b[0m         mismatched_keys,\n\u001b[1;32m   4012\u001b[0m         offload_index,\n\u001b[1;32m   4013\u001b[0m         error_msgs,\n\u001b[0;32m-> 4014\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4021\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4025\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4026\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4033\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4034\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:4525\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assign_to_params_buffers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4522\u001b[0m         assign_to_params_buffers \u001b[38;5;241m=\u001b[39m check_support_param_buffer_assignment(\n\u001b[1;32m   4523\u001b[0m             model_to_load, state_dict, start_prefix\n\u001b[1;32m   4524\u001b[0m         )\n\u001b[0;32m-> 4525\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\n\u001b[1;32m   4527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4529\u001b[0m \u001b[38;5;66;03m# force memory release\u001b[39;00m\n\u001b[1;32m   4530\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:761\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, assign_to_params_buffers)\n\u001b[0;32m--> 761\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:759\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:759\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 759 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:759\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/transformers/modeling_utils.py:755\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 755\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:2096\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[1;32m   2095\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2096\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   2098\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswapping\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_swap_tensors \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sae_name = \"gemma-scope-2b-pt-res-canonical\"\n",
    "# sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in range(11)]  # 0 through 10\n",
    "# sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in [5]]  # 0 through 10\n",
    "sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in range(5)]  # 0 through 10\n",
    "\n",
    "save_sae_activations(sae_name, sae_ids, alpaca_data_10000, suffix = \"alpaca_10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.25s/it]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b-it into HookedTransformer\n",
      "SAE ID: layer_0/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 67218\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_0/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_1/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 64476\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_1/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_2/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 94561\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_2/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_3/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 44623\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_3/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_4/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 92794\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_4/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_5/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 54157\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_5/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_6/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 58572\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_6/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_7/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 54163\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_7/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_8/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 59694\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_8/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_9/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 55206\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_9/width_16k/canonical_advbench.pt'\n",
      "---\n",
      "SAE ID: layer_10/width_16k/canonical\n",
      "Shape of stacked tensor: torch.Size([520, 16384])\n",
      "Total number of non-zero activations: 73459\n",
      "Stacked SAE activations saved to '../data/sae_acts/gemma-scope-2b-pt-res-canonical/layer_10/width_16k/canonical_advbench.pt'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "gemma2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gemma-2-2b-it\", device=device)\n",
    "\n",
    "for sae_id in sae_ids:\n",
    "    gemma2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=sae_name,\n",
    "        sae_id=sae_id,\n",
    "        device=str(device),\n",
    "    )\n",
    "\n",
    "    all_sae_acts_post = []\n",
    "\n",
    "    for item in advbench_data:\n",
    "        prompt = item['instruction']\n",
    "        \n",
    "        # Get top activations on final token\n",
    "        _, cache = gemma2.run_with_cache_with_saes(\n",
    "            prompt,\n",
    "            saes=[gemma2_sae],\n",
    "            stop_at_layer=gemma2_sae.cfg.hook_layer + 1,\n",
    "        )\n",
    "        sae_acts_post = cache[f\"{gemma2_sae.cfg.hook_name}.hook_sae_acts_post\"][0, -1, :]\n",
    "        all_sae_acts_post.append(sae_acts_post)\n",
    "\n",
    "    # Stack all sae_acts_post tensors\n",
    "    stacked_sae_acts_post = torch.stack(all_sae_acts_post)\n",
    "\n",
    "    print(f\"SAE ID: {sae_id}\")\n",
    "    print(f\"Shape of stacked tensor: {stacked_sae_acts_post.shape}\")\n",
    "    print(f\"Total number of non-zero activations: {(stacked_sae_acts_post != 0).sum().item()}\")\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(f'../data/sae_acts/{sae_name}/{sae_id}', exist_ok=True)\n",
    "\n",
    "    # Save the stacked_sae_acts_post tensor\n",
    "    torch.save(stacked_sae_acts_post.cpu(), f'../data/sae_acts/{sae_name}/{sae_id}_advbench.pt')\n",
    "\n",
    "    # Print confirmation message\n",
    "    print(f\"Stacked SAE activations saved to '../data/sae_acts/{sae_name}/{sae_id}_advbench.pt'\")\n",
    "    print(\"---\")\n",
    "\n",
    "    del stacked_sae_acts_post\n",
    "    del gemma2_sae\n",
    "    t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get average activations for each sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/sae_lens/sae.py:143: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "\n",
    "gpt2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "gpt2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",\n",
    "    device=str(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.73k/2.73k [00:00<00:00, 87.8kB/s]\n",
      "Downloading readme: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.35k/7.35k [00:00<00:00, 180kB/s]\n",
      "/n/data2/hms/dbmi/sunyaev/lab/dlee/.cache/pypoetry/virtualenvs/refusal-direction-f5Ymycjl-py3.12/lib/python3.12/site-packages/sae_lens/training/activations_store.py:246: UserWarning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "gpt2_act_store = ActivationsStore.from_sae(\n",
    "    model=gpt2,\n",
    "    sae=gpt2_sae,\n",
    "    streaming=True,\n",
    "    store_batch_size_prompts=16,\n",
    "    n_batches_in_buffer=32,\n",
    "    device=str(device),\n",
    ")\n",
    "\n",
    "# Example of how you can use this:\n",
    "tokens = gpt2_act_store.get_batch_tokens()\n",
    "assert tokens.shape == (gpt2_act_store.store_batch_size_prompts, gpt2_act_store.context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:25<00:00, 15.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_frac_active(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    act_store: ActivationsStore,\n",
    "    # latent_idx: int,\n",
    "    total_batches: int = 400,\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays the activation histogram for a particular latent, computed across `total_batches` batches from `act_store`.\n",
    "    \"\"\"\n",
    "    sae_acts_post_hook_name = f\"{sae.cfg.hook_name}.hook_sae_acts_post\"\n",
    "    all_positive_acts = []\n",
    "\n",
    "    all_positive_acts = t.zeros(sae.cfg.d_sae, device=device)\n",
    "    total_acts = 0\n",
    "\n",
    "    for i in tqdm(range(total_batches)):\n",
    "        tokens = act_store.get_batch_tokens()\n",
    "        _, cache = model.run_with_cache_with_saes(\n",
    "            tokens,\n",
    "            saes=[sae],\n",
    "            stop_at_layer=sae.cfg.hook_layer + 1,\n",
    "            names_filter=[sae_acts_post_hook_name],\n",
    "        )\n",
    "        acts = cache[sae_acts_post_hook_name]\n",
    "        all_positive_acts += (acts > 0).sum(dim=(0, 1))\n",
    "        total_acts += acts.shape[0] * acts.shape[1]\n",
    "\n",
    "    frac_active = all_positive_acts / total_acts\n",
    "\n",
    "    return frac_active\n",
    "\n",
    "\n",
    "frac_active = get_frac_active(gpt2, gpt2_sae, gpt2_act_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1123, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_active[3731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_grad_enabled(False)\n",
    "\n",
    "sae_name = \"gemma-scope-2b-pt-res-canonical\"\n",
    "sae_ids = [f\"layer_{layer}/width_16k/canonical\" for layer in range(11)]  # 0 through 10\n",
    "\n",
    "gemma2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gemma-2-2b-it\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [03:40<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_0/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0323, 0.0013, 0.0100,  ..., 0.0024, 0.0030, 0.0010], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [05:25<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_1/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0011, 0.0016, 0.0276,  ..., 0.0004, 0.0009, 0.0008], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [07:08<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_2/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0012, 0.0075, 0.0009,  ..., 0.0008, 0.0064, 0.0012], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [08:50<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_3/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0032, 0.0028, 0.0156,  ..., 0.0007, 0.0013, 0.0059], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [10:35<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_4/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0007, 0.0138, 0.0029,  ..., 0.0040, 0.0014, 0.0067], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [12:33<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_5/width_16k/canonical\n",
      "Fraction of activations: tensor([1.2868e-02, 1.6076e-02, 1.8198e-03,  ..., 8.3618e-05, 1.6998e-04,\n",
      "        4.5691e-03], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [14:04<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_6/width_16k/canonical\n",
      "Fraction of activations: tensor([1.7288e-04, 2.4805e-03, 3.6662e-03,  ..., 9.7809e-05, 3.8969e-03,\n",
      "        3.2462e-03], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [15:48<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_7/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0008, 0.0101, 0.0005,  ..., 0.0010, 0.0026, 0.0043], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [17:32<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE ID: layer_8/width_16k/canonical\n",
      "Fraction of activations: tensor([0.0034, 0.0097, 0.0066,  ..., 0.0054, 0.0058, 0.0058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████████████▌                                                                                                     | 122/400 [05:53<13:28,  2.91s/it]"
     ]
    }
   ],
   "source": [
    "for sae_id in sae_ids:\n",
    "    gemma2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=sae_name,\n",
    "        sae_id=sae_id,\n",
    "        device=str(device),\n",
    "    )\n",
    "\n",
    "    gemma2_act_store = ActivationsStore.from_sae(\n",
    "        model=gemma2,\n",
    "        sae=gemma2_sae,\n",
    "        streaming=True,\n",
    "        store_batch_size_prompts=16,\n",
    "        n_batches_in_buffer=32,\n",
    "        device=str(device),\n",
    "    )\n",
    "\n",
    "    frac_active = get_frac_active(gemma2, gemma2_sae, gemma2_act_store)\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(f'../data/sae_acts/{sae_name}/{sae_id}', exist_ok=True)\n",
    "\n",
    "    # Save the stacked_sae_acts_post tensor\n",
    "    t.save(frac_active, f'../data/sae_acts/{sae_name}/{sae_id}/frac_active.pt')\n",
    "    print(f\"SAE ID: {sae_id}\")\n",
    "    print(f\"Fraction of activations: {frac_active}\")\n",
    "\n",
    "    del gemma2_sae\n",
    "    t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gemma2_sae\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
